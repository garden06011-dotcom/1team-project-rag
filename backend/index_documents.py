#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë¬¸ì„œ ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

data/documents/ í´ë”ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì½ì–´ì„œ
ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from rag.document_loader import DirectoryLoader, TextSplitter
from rag.embeddings import BGEEmbeddings
from rag.vector_store import ChromaVectorStore


def main():
    print("=" * 70)
    print("ğŸ“š ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘")
    print("=" * 70)

    # 1. ë¬¸ì„œ í´ë” ê²½ë¡œ
    documents_path = Path(__file__).parent / "data" / "documents"
    print(f"\nğŸ“ ë¬¸ì„œ í´ë”: {documents_path}")

    # 2. ë¬¸ì„œ ë¡œë“œ
    print("\nğŸ” 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”© ì¤‘...")
    loader = DirectoryLoader(
        directory_path=str(documents_path),
        supported_extensions=[".txt", ".pdf", ".docx", ".md"]
    )

    try:
        documents = loader.load()
        print(f"   âœ“ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

        if not documents:
            print("\nâš ï¸  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. data/documents/ í´ë”ì— ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return

        # ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
        print("\nğŸ“„ ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡:")
        for i, doc in enumerate(documents, 1):
            source = doc.metadata.get("source", "unknown")
            content_preview = doc.page_content[:50].replace("\n", " ")
            print(f"   {i}. {source} - {content_preview}...")

    except Exception as e:
        print(f"\nâŒ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 3. í…ìŠ¤íŠ¸ ë¶„í• 
    print("\nâœ‚ï¸  2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘...")
    splitter = TextSplitter(
        chunk_size=500,      # 500ì ë‹¨ìœ„ë¡œ ë¶„í• 
        chunk_overlap=100,   # 100ì ì˜¤ë²„ë©
        separator="\n\n"     # ë¬¸ë‹¨ ê¸°ì¤€ ë¶„í• 
    )

    try:
        split_docs = splitter.split_documents(documents)
        print(f"   âœ“ {len(split_docs)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")

        # ì²­í¬ í†µê³„
        total_chars = sum(len(doc.page_content) for doc in split_docs)
        avg_chars = total_chars / len(split_docs) if split_docs else 0
        print(f"   - ì´ ë¬¸ì ìˆ˜: {total_chars:,}ì")
        print(f"   - í‰ê·  ì²­í¬ í¬ê¸°: {avg_chars:.0f}ì")

    except Exception as e:
        print(f"\nâŒ í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤íŒ¨: {e}")
        return

    # 4. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    print("\nğŸ¤– 3ë‹¨ê³„: BGE-M3-KO ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        embeddings_model = BGEEmbeddings()
        print(f"   âœ“ ì„ë² ë”© ì°¨ì›: {embeddings_model.get_embedding_dimension()}")
    except Exception as e:
        print(f"\nâŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 5. ë¬¸ì„œ ì„ë² ë”©
    print("\nğŸ”¢ 4ë‹¨ê³„: ë¬¸ì„œ ì„ë² ë”© ì¤‘...")
    try:
        texts = [doc.page_content for doc in split_docs]
        metadatas = [doc.metadata for doc in split_docs]

        print(f"   - {len(texts)}ê°œ ì²­í¬ ì„ë² ë”© ì‹œì‘...")
        print("   (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...)")

        doc_embeddings = embeddings_model.embed_documents(texts)
        print(f"   âœ“ {len(doc_embeddings)}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")

    except Exception as e:
        print(f"\nâŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return

    # 6. ChromaDBì— ì €ì¥
    print("\nğŸ’¾ 5ë‹¨ê³„: ChromaDBì— ì €ì¥ ì¤‘...")
    try:
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
        vector_store = ChromaVectorStore(
            collection_name="commercial_analysis_docs"
        )

        # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚­ì œ
        existing_count = vector_store.get_document_count()
        if existing_count > 0:
            print(f"   âš ï¸  ê¸°ì¡´ ë°ì´í„° {existing_count}ê°œ ë°œê²¬")
            print("   - ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì¤‘...")
            vector_store.delete_collection()

            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            vector_store = ChromaVectorStore(
                collection_name="commercial_analysis_docs"
            )
            print("   âœ“ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")

        # ë¬¸ì„œ ì¶”ê°€
        ids = vector_store.add_documents(
            texts=texts,
            embeddings=doc_embeddings,
            metadatas=metadatas
        )

        print(f"   âœ“ {len(ids)}ê°œ ë¬¸ì„œ ChromaDBì— ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print(f"\nâŒ ChromaDB ì €ì¥ ì‹¤íŒ¨: {e}")
        return

    # 7. ê²€ì¦
    print("\nâœ… 6ë‹¨ê³„: ì¸ë±ì‹± ê²€ì¦ ì¤‘...")
    try:
        final_count = vector_store.get_document_count()
        print(f"   âœ“ ìµœì¢… ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {final_count}ê°œ")

        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰...")
        test_query = "ê°•ë‚¨ì—ì„œ ì¹´í˜ ì°½ì—…"
        test_embedding = embeddings_model.embed_query(test_query)
        results = vector_store.search(test_embedding, top_k=3)

        print(f"   - ê²€ìƒ‰ ì¿¼ë¦¬: '{test_query}'")
        print(f"   - ê²€ìƒ‰ ê²°ê³¼: {len(results['documents'])}ê°œ")

        if results["documents"]:
            print("\n   ğŸ“„ ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:")
            for i, (doc, metadata, distance) in enumerate(zip(
                results["documents"][:2],
                results["metadatas"][:2],
                results["distances"][:2]
            ), 1):
                similarity = 1 - (distance / 2)
                source = metadata.get("source", "unknown")
                preview = doc[:80].replace("\n", " ")
                print(f"   [{i}] {source} (ìœ ì‚¬ë„: {similarity:.3f})")
                print(f"       {preview}...")

    except Exception as e:
        print(f"\nâš ï¸  ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")

    # ì™„ë£Œ
    print("\n" + "=" * 70)
    print("ğŸ‰ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nâœ… ì´ {len(split_docs)}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"âœ… ì´ì œ RAG ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print(f"\nğŸ’¡ ì„œë²„ ì‹œì‘: cd backend && uvicorn main:app --reload --port 8001")
    print(f"ğŸ’¡ í…ŒìŠ¤íŠ¸: POST http://localhost:8001/api/rag-chat-stream")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        print(f"\n\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

